{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:21:37.621836Z",
     "start_time": "2025-12-09T06:21:34.754840Z"
    }
   },
   "cell_type": "code",
   "source": "from datasets import load_dataset, Dataset, concatenate_datasets",
   "id": "88518006f7edcef9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DuReader2.0",
   "id": "37e954f29598a623"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "input_path = \"\"",
   "id": "de04959287316fd3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = load_dataset(\"json\", data_files=input_path)[\"train\"]",
   "id": "f5d9f66a1bf69036"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "total, baike, zhidao, tieba, zhihu = 0, 0, 0, 0, 0\n",
    "for data in dataset:\n",
    "    for document in data[\"documents\"]:\n",
    "        total += 1\n",
    "        title = document[\"title\"]\n",
    "        if title.endswith(\"_百度百科\"):\n",
    "            baike += 1\n",
    "        elif title.endswith(\"_百度知道\"):\n",
    "            zhidao += 1\n",
    "        elif title.endswith(\"_百度贴吧\"):\n",
    "            tieba += 1\n",
    "        elif title.endswith(\" - 知乎\"):\n",
    "            zhihu += 1\n",
    "total, baike, zhidao, tieba, zhihu"
   ],
   "id": "b92a6d76274aa08"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Baidu Tieba",
   "id": "73505fd3fb0571d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:21:42.310279Z",
     "start_time": "2025-12-09T06:21:42.303505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_path = \"\"\n",
    "output_path = \"\""
   ],
   "id": "914271a93505c753",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:22:11.941666Z",
     "start_time": "2025-12-09T06:21:43.028640Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_dataset(\"json\", data_files=input_path)[\"train\"]",
   "id": "14a03767e5e2d208",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 136208 examples [00:23, 5911.90 examples/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:22:33.561848Z",
     "start_time": "2025-12-09T06:22:26.671386Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_df = dataset.to_pandas()",
   "id": "58101b5f49c8e145",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:22:33.593067Z",
     "start_time": "2025-12-09T06:22:33.584506Z"
    }
   },
   "cell_type": "code",
   "source": "processed_data = []",
   "id": "c75e09b73895facb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:22:48.574420Z",
     "start_time": "2025-12-09T06:22:43.013825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for _, row in dataset_df.iterrows():\n",
    "    documents = row[\"documents\"]\n",
    "    for document in documents:\n",
    "        if document[\"title\"].endswith(\"_百度贴吧\"):\n",
    "            title = document[\"title\"].removesuffix(\"_百度贴吧\")\n",
    "            if '_' in title:\n",
    "                title = title.rsplit('_', 1)[0]\n",
    "            elif '【' in title:\n",
    "                title = title.rsplit('【', 1)[0]\n",
    "            else:\n",
    "                continue\n",
    "            if len(document[\"paragraphs\"]) >= 2:\n",
    "                text = document[\"paragraphs\"][1]\n",
    "                if text == \"下载贴吧APP看高清直播、视频!\" or text == \"登录百度帐号\" or text == \"我的游戏 推荐游戏\" \\\n",
    "                        or \"活动截止\" in text or text == \"贴吧页面意见反馈 违规贴吧举报反馈通道 贴吧违规信息处理公示\" \\\n",
    "                        or text == \"百度小说人气榜\" or text == \"百度移动游戏玩家均可认证(限百度账号),去领取\":\n",
    "                    continue\n",
    "                processed_data.append({\n",
    "                    \"title\": title,\n",
    "                    \"text\": document[\"paragraphs\"][1]\n",
    "                })"
   ],
   "id": "bc34d3493105fc58",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:22:51.928910Z",
     "start_time": "2025-12-09T06:22:51.845592Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = Dataset.from_list(processed_data)",
   "id": "9c58cc791fc9a936",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:22:52.278775Z",
     "start_time": "2025-12-09T06:22:52.263326Z"
    }
   },
   "cell_type": "code",
   "source": "len(dataset)",
   "id": "192b7ff77d88f02d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12949"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset.to_parquet(output_path)",
   "id": "f4ab3d41b6e85608"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Baidu Zhidao",
   "id": "543817cd363aab3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "input_path = \"\"\n",
    "output_path = \"\""
   ],
   "id": "eba0524b2b78f8f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = load_dataset(\"json\", data_files=input_path)[\"train\"]",
   "id": "191412370675860d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(dataset)",
   "id": "15c98e4987319aec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "zhidao = 0\n",
    "for data in dataset:\n",
    "    documents = data[\"documents\"]\n",
    "    zhidao += len(documents)\n",
    "zhidao"
   ],
   "id": "19848056c8315793"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset_df = dataset.to_pandas()",
   "id": "df1657b94eb7adb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for _, row in dataset_df.iterrows():\n",
    "    document = row[\"documents\"][0]\n",
    "    title = document[\"title\"]\n",
    "    text = document[\"paragraphs\"][0]\n",
    "    processed_data.append({\n",
    "        \"title\": title,\n",
    "        \"text\": text\n",
    "    })"
   ],
   "id": "b7192062a8ee6b71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = Dataset.from_list(processed_data)",
   "id": "86ae70859b9456b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(dataset)",
   "id": "4f41a6e262c5f210"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset.to_parquet(output_path)",
   "id": "8c94c4613a5d8dde"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Baidu Baike",
   "id": "e37e8e75aea10cfc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "input_path = \"\"\n",
    "output_path = \"\""
   ],
   "id": "73f0240112ab5e40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = load_dataset(\"json\", data_files=input_path)[\"train\"]",
   "id": "644e3cabb244a628"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(dataset)",
   "id": "a8ca3cbc42565763"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process(examples: dict[str, list]) -> dict[str, list]:\n",
    "    summaries = examples[\"summary\"]\n",
    "    sections_all = examples[\"sections\"]\n",
    "    texts = []\n",
    "    for summary, sections in zip(summaries, sections_all):\n",
    "        text = \"\"\n",
    "        if summary is not None:\n",
    "            text += summary + \"\\n\"\n",
    "        for section in sections:\n",
    "            text += section[\"title\"] + \"\\n\" + section[\"content\"] + \"\\n\"\n",
    "        text = text.strip(\"\\n\")\n",
    "        texts.append(text)\n",
    "    examples[\"text\"] = texts\n",
    "    return examples"
   ],
   "id": "59960be74503a202"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "current_column_names = dataset.column_names\n",
    "current_column_names.remove(\"title\")"
   ],
   "id": "589c158ac7f63a8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = dataset.map(process, batched=True, batch_size=None, remove_columns=current_column_names)",
   "id": "bd8c02f007f837e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset.to_parquet(output_path)",
   "id": "40f33d739d0fd5b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Zhihu",
   "id": "f07f2d043c083101"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T05:30:38.482820Z",
     "start_time": "2025-12-01T05:30:38.476198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dir = \"\"\n",
    "output_path = \"\""
   ],
   "id": "74e62d1b4651411d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T05:30:41.486758Z",
     "start_time": "2025-12-01T05:30:39.546937Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_dataset(\"json\", data_dir=input_dir)",
   "id": "b4c5bb6d7f9eb1dd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T05:30:41.508696Z",
     "start_time": "2025-12-01T05:30:41.501203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_dataset = dataset[\"test\"]\n",
    "val_dataset = dataset[\"validation\"]\n",
    "test_keys = dataset[\"test\"][\"uniqueKey\"]\n",
    "val_keys = dataset[\"validation\"][\"uniqueKey\"]"
   ],
   "id": "34ce02690c98efe",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T05:30:42.442505Z",
     "start_time": "2025-12-01T05:30:41.975247Z"
    }
   },
   "cell_type": "code",
   "source": "intersection = set(test_keys) & set(val_keys)",
   "id": "14b64536c293ae2a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T05:30:44.799090Z",
     "start_time": "2025-12-01T05:30:44.749357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_dataset = val_dataset.filter(\n",
    "    lambda examples: [key not in intersection for key in examples[\"uniqueKey\"]],\n",
    "    batched=True,\n",
    "    batch_size=None\n",
    ")"
   ],
   "id": "50563f679c7f604e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T05:30:46.911284Z",
     "start_time": "2025-12-01T05:30:46.895508Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = concatenate_datasets([test_dataset, val_dataset])",
   "id": "2d78b7ace78ebc84",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T05:30:53.769912Z",
     "start_time": "2025-12-01T05:30:53.761886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process(examples: dict[str, list]) -> dict[str, list]:\n",
    "    examples[\"text\"] = [content.removeprefix(title).strip() for title, content in zip(examples[\"title\"], examples[\"content\"])]\n",
    "    return examples"
   ],
   "id": "46838ce05fb8650b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T05:30:55.071978Z",
     "start_time": "2025-12-01T05:30:55.060852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_column_names = dataset.column_names\n",
    "current_column_names.remove(\"title\")"
   ],
   "id": "6e8541981039388e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T05:30:57.370689Z",
     "start_time": "2025-12-01T05:30:55.970936Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = dataset.map(process, batched=True, batch_size=None, remove_columns=current_column_names)",
   "id": "4ee77f10d56b6705",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 19991/19991 [00:01<00:00, 14457.05 examples/s]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T05:31:01.380628Z",
     "start_time": "2025-12-01T05:30:59.991593Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.to_parquet(output_path)",
   "id": "42d88758be41d364",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 20/20 [00:01<00:00, 14.64ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104411033"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Weibo",
   "id": "3ca17abebaa52578"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:23:49.361979Z",
     "start_time": "2025-12-09T06:23:49.355194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dir = \"\"\n",
    "output_path = \"\""
   ],
   "id": "7b824cb0dcb490d6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:24:20.966849Z",
     "start_time": "2025-12-09T06:23:50.765712Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_dataset(\"csv\", data_dir=input_dir)[\"train\"]",
   "id": "d2d6b27521120ab0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 1756/1756 [00:00<00:00, 7608.93files/s]\n",
      "Generating train split: 87800 examples [00:04, 19647.85 examples/s]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:24:48.477246Z",
     "start_time": "2025-12-09T06:24:48.464313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "def filter_function(examples: dict[str, list]) -> list[bool]:\n",
    "    flags = []\n",
    "    titles = examples[\"话题\"]\n",
    "    contents_all = examples[\"内容\"]\n",
    "    unique_titles = set()\n",
    "    for title, contents in zip(titles, contents_all):\n",
    "        if len(title) < 4:\n",
    "            flags.append(False)\n",
    "            continue\n",
    "        flag = False\n",
    "        if contents is not None:\n",
    "            contents = literal_eval(contents)\n",
    "            for content in contents:\n",
    "                comments = content[\"comments\"]\n",
    "                if len(comments) != 0:\n",
    "                    for comment in comments:\n",
    "                        if len(comment) > 10:\n",
    "                            flag = True\n",
    "                            break\n",
    "                if flag:\n",
    "                    break\n",
    "        if flag:\n",
    "            if title in unique_titles:\n",
    "                flag = False\n",
    "            unique_titles.add(title)\n",
    "        flags.append(flag)\n",
    "    return flags"
   ],
   "id": "122d7e0f3a2bbad1",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:24:58.801547Z",
     "start_time": "2025-12-09T06:24:49.253527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = dataset.filter(\n",
    "    filter_function,\n",
    "    batched=True,\n",
    "    batch_size=None\n",
    ")"
   ],
   "id": "6dfb558d7c70469e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 87800/87800 [00:09<00:00, 9230.48 examples/s]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:25:00.163969Z",
     "start_time": "2025-12-09T06:25:00.154346Z"
    }
   },
   "cell_type": "code",
   "source": "len(dataset)",
   "id": "198e0bb977e2fc8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6041"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:37:04.134544Z",
     "start_time": "2025-12-09T06:37:03.877304Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_df = dataset.to_pandas()",
   "id": "a0e4bb3d1e943d30",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:37:23.000091Z",
     "start_time": "2025-12-09T06:37:22.954002Z"
    }
   },
   "cell_type": "code",
   "source": "processed_data = []",
   "id": "e9a0333f7da9a583",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T07:12:19.343381Z",
     "start_time": "2025-12-09T07:12:19.329211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contents = literal_eval(dataset_df.iloc[0][\"内容\"])\n",
    "contents[0][\"comments\"]"
   ],
   "id": "e532172cad7b3681",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['：就怕特没谱随时变卦 毕竟他不太正常',\n",
       " '：军工立大功了',\n",
       " '：就是只保留跟其他国家一样的10%。其他的再谈。',\n",
       " '：90天内暂停实施，90天后还需要谈判，是这个意思吧',\n",
       " '：美国佬，尤其是特朗普那个傻蛋，根本不可信！要当心其出尔反尔！',\n",
       " '：先辈未曾低头，吾辈岂能弯腰',\n",
       " '：谈判和斗争继续。但是给了大家踹口气。存在特没谱随时变卦，所以对美出口企业，一定要抛弃把美国市场作为主要市场的行商策略，当然每个老板有自己的策略，无可厚非。只是要未雨绸缪',\n",
       " '：这个确实超预期，只剩下10%的关税了。',\n",
       " '：目测二季度订单要爆，延续到三季度头～鬼知道90天之后又有什么幺蛾子，估计四季度会落一点']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T07:13:54.450777Z",
     "start_time": "2025-12-09T07:13:49.615473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for _, row in dataset_df.iterrows():\n",
    "    title = row[\"话题\"]\n",
    "    contents = literal_eval(row[\"内容\"])\n",
    "    for content in contents:\n",
    "        comments = content[\"comments\"]\n",
    "        if len(comments) != 0:\n",
    "            for comment in comments:\n",
    "                if len(comment) > 10:\n",
    "                    processed_data.append({\n",
    "                        \"title\": title,\n",
    "                        \"text\": comment.removeprefix(\"：\")\n",
    "                    })\n",
    "dataset = Dataset.from_list(processed_data)"
   ],
   "id": "6be2ce50e4dbab4f",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T07:13:58.262097Z",
     "start_time": "2025-12-09T07:13:58.252389Z"
    }
   },
   "cell_type": "code",
   "source": "len(dataset)",
   "id": "5bfd62019d463d7b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92399"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T07:14:46.987165Z",
     "start_time": "2025-12-09T07:14:46.876472Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.to_parquet(output_path)",
   "id": "9e0901c9ae829be7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 15.70ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10271029"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RedNote",
   "id": "e32148d30daec00f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "input_dir = \"\"\n",
    "output_path = \"\""
   ],
   "id": "565a1cfd9aab27be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = load_dataset(\"parquet\", data_dir=input_dir)",
   "id": "12eaccd56c950b79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "dataset = concatenate_datasets([train_dataset, test_dataset, val_dataset])"
   ],
   "id": "3a4ca151d2032cfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def filter_function(examples: dict[str, list]) -> list[bool]:\n",
    "    flags = []\n",
    "    titles = examples[\"title\"]\n",
    "    unique_titles = set()\n",
    "    for title in titles:\n",
    "        if len(title) <= 5 or title in unique_titles:\n",
    "            flags.append(False)\n",
    "            continue\n",
    "        unique_titles.add(title)\n",
    "        flags.append(True)\n",
    "    return flags"
   ],
   "id": "65b9a96e2d8354fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset = dataset.filter(\n",
    "    filter_function,\n",
    "    batched=True,\n",
    "    batch_size=None\n",
    ")"
   ],
   "id": "6d45508a83494145"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(dataset)",
   "id": "f10705c262b84fb6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "new_data = []\n",
    "for item in dataset:\n",
    "    title = item['title']\n",
    "    comments = item['comments']\n",
    "    if comments:\n",
    "        for comment in comments:\n",
    "            if len(comment) >= 10:\n",
    "                new_data.append({'title': title, 'text': comment})\n",
    "dataset = Dataset.from_list(new_data)"
   ],
   "id": "48ba62d835af0df8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(dataset)",
   "id": "7d5c59addaecb916"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset.to_parquet(output_path)",
   "id": "d43dbc8e66eb1df6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Douban",
   "id": "bd6198267e8b8852"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "input_path = \"\"\n",
    "output_path = \"\""
   ],
   "id": "10ad21cec660f253"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = load_dataset(\"csv\", data_files=input_path)[\"train\"]",
   "id": "81a127e5cac7c81f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset = dataset.filter(\n",
    "    lambda examples: [comment and len(comment) >= 10 for comment in examples[\"Comment\"]],\n",
    "    batched=True,\n",
    "    batch_size=None\n",
    ")"
   ],
   "id": "b4c20144c451d01a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(dataset)",
   "id": "cad030c51eabf657"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset.to_parquet(output_path)",
   "id": "4a06bff1adefb968"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CSL",
   "id": "bbd677a955d10055"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "input_path = \"\"\n",
    "output_path = \"\""
   ],
   "id": "1039c0198138964"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import csv\n",
    "from datasets import Features, Value\n",
    "\n",
    "csl_features = Features({\n",
    "    \"title\": Value(\"string\"),\n",
    "    \"abstract\": Value(\"string\"),\n",
    "    \"keywords\": Value(\"string\"),\n",
    "    \"category\": Value(\"string\"),\n",
    "    \"discipline\": Value(\"string\")\n",
    "})\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=input_path, delimiter=\"\\t\", column_names=csl_features.keys(),\n",
    "                       quoting=csv.QUOTE_NONE)[\"train\"]"
   ],
   "id": "a5f127976e2fd571"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = dataset.remove_columns([\"keywords\", \"category\", \"discipline\"])",
   "id": "db5373f52d3991e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(dataset)",
   "id": "b6a8905b190547b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset.to_parquet(output_path)",
   "id": "598df6b462ecbd64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CLTS",
   "id": "12fbd0cbe862e0a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T07:07:51.124262Z",
     "start_time": "2025-11-28T07:07:51.116535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_source_input_path = \"\"\n",
    "train_target_input_path = \"\"\n",
    "valid_source_input_path = \"\"\n",
    "valid_target_input_path = \"\"\n",
    "test_source_input_path = \"\"\n",
    "test_target_input_path = \"\"\n",
    "output_path = \"\""
   ],
   "id": "ea6733dfb02a685c",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T07:14:08.136567Z",
     "start_time": "2025-11-28T07:11:43.470925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_source_dataset = load_dataset(\"text\", data_files=train_source_input_path)[\"train\"]\n",
    "train_target_dataset = load_dataset(\"text\", data_files=train_target_input_path)[\"train\"]\n",
    "valid_source_dataset = load_dataset(\"text\", data_files=valid_source_input_path)[\"train\"]\n",
    "valid_target_dataset = load_dataset(\"text\", data_files=valid_target_input_path)[\"train\"]\n",
    "test_source_dataset = load_dataset(\"text\", data_files=test_source_input_path)[\"train\"]\n",
    "test_target_dataset = load_dataset(\"text\", data_files=test_target_input_path)[\"train\"]"
   ],
   "id": "6f0fd4dce2be96d4",
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T07:14:23.253715Z",
     "start_time": "2025-11-28T07:14:23.232492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 合并所有 source 和 target 数据集\n",
    "source_dataset = concatenate_datasets([train_source_dataset, valid_source_dataset, test_source_dataset])\n",
    "target_dataset = concatenate_datasets([train_target_dataset, valid_target_dataset, test_target_dataset])"
   ],
   "id": "merge_all_clts_datasets",
   "outputs": [],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T07:14:25.251985Z",
     "start_time": "2025-11-28T07:14:25.242835Z"
    }
   },
   "cell_type": "code",
   "source": "len(source_dataset)",
   "id": "ee90e43d6a7e5b04",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185397"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T07:14:27.060781Z",
     "start_time": "2025-11-28T07:14:27.053256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "special_white_space_chars = [\n",
    "    '\\t', '\\v', '\\f', '\\xa0', '\\u00a0', '\\u2000', '\\u2001', '\\u2002', '\\u2003', '\\u2004', '\\u2005', '\\u2006', '\\u2007',\n",
    "    '\\u2008', '\\u2009', '\\u200a', '\\u200b', '\\u202f', '\\u205f', '\\u3000', '\\ufeff', chr(4447), chr(4448), chr(12644),\n",
    "    \"&nbsp;\", \"&ensp;\", \"&rdquo;\", \"&thinsp;\", \"&zwnj;\", \"&zwj;\"\n",
    "]"
   ],
   "id": "d330da5c56f4cfd3",
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T07:14:29.636624Z",
     "start_time": "2025-11-28T07:14:29.622069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "def process(examples: dict[str, list], is_source_dataset: bool = False) -> dict[str, list]:\n",
    "    texts = []\n",
    "\n",
    "    suf_pre = [\"（原题\", \"(原题\", \"（原文题\", \"(原文题\", \"（原标题\", \"(原标题\", \"（本文原题\", \"(本文原题\", \"（本文标题\",\n",
    "               \"(本文标题\", \"（原文标题\", \"(原文标题\", \"原标题：\", \"原题为\"]\n",
    "    suf_pattern = re.compile(r'(' + '|'.join(re.escape(p) for p in suf_pre) + r').*$')\n",
    "\n",
    "    for text in examples[\"text\"]:\n",
    "        # 1. 删除特殊空白字符与首尾空白符\n",
    "        for char in special_white_space_chars:\n",
    "            text = text.replace(char, '').strip()\n",
    "\n",
    "        # 2. 删除中文标点符号周围的空格\n",
    "        chinese_punctuations = r'[\\u3001\\u3002\\uff0c\\uff0e\\uff1a\\uff1b\\uff1f\\uff01\\u201c\\u201d\\u2018\\u2019\\uff08\\uff09\\u300a\\u300b\\u3008\\u3009\\u3010\\u3011\\u300e\\u300f\\u300c\\u300d\\ufe43\\ufe44\\u3014\\u3015]'\n",
    "        text = re.sub(r'\\s+(' + chinese_punctuations + ')', r'\\1', text)\n",
    "        text = re.sub(r'(' + chinese_punctuations + r')\\s+', r'\\1', text)\n",
    "\n",
    "        # 3. 删除英文标点符号前的所有连续空格\n",
    "        english_punctuations = re.escape(string.punctuation)\n",
    "        text = re.sub(r'\\s+([' + english_punctuations + '])', r'\\1', text)\n",
    "\n",
    "        # 4. 如果一个空格不在两个英文字母之间，并且周围也没有另一个空格，删除该空格\n",
    "        text = re.sub(r'(?<=[^a-zA-Z ]) | (?=[^a-zA-Z ])', '', text)\n",
    "\n",
    "        # 5. 将剩余的连续空格合并为一个空格\n",
    "        text = re.sub(r' +', ' ', text)\n",
    "\n",
    "        # 6. 其他清洗\n",
    "        if is_source_dataset:\n",
    "            text = text.removesuffix(\"(本文来自澎湃新闻，更多原创资讯请下载“澎湃新闻”APP)\")\n",
    "            # 删除以 suf_pre 开头的后缀\n",
    "            text = suf_pattern.sub('', text).strip()\n",
    "            # 如 （应被访者要求，文中何莹莹、张春梅、陈婉均为化名，原题为《警惕网拍模特招聘中的高价“模卡”骗局》） 、\n",
    "            # 澎湃新闻（www.thepaper.cn）记者从上海一中院获悉，该院将择日对此案作出宣判、\n",
    "            # 、（澎湃新闻记者 俞凯 整理） 等的此类没有被删除\n",
    "\n",
    "        texts.append(text)\n",
    "\n",
    "    examples[\"text\"] = texts\n",
    "\n",
    "    return examples"
   ],
   "id": "f9d755c18cec4a32",
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T07:14:46.346153Z",
     "start_time": "2025-11-28T07:14:46.336846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "select_ids = []\n",
    "\n",
    "\n",
    "def clean_filter(examples: dict[str, list]) -> list[bool]:\n",
    "    flags = []\n",
    "    global select_ids\n",
    "    for i, text in enumerate(examples[\"text\"]):\n",
    "        if text.startswith(\"本文原标题：\"):\n",
    "            flags.append(False)\n",
    "        else:\n",
    "            flags.append(True)\n",
    "            select_ids.append(i)\n",
    "    return flags"
   ],
   "id": "93d692e006d4b14f",
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T07:15:05.880933Z",
     "start_time": "2025-11-28T07:15:04.802488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_dataset = target_dataset.map(process, batched=True, batch_size=None)\n",
    "target_dataset = target_dataset.filter(clean_filter, batched=True, batch_size=None)\n",
    "source_dataset = source_dataset.select(select_ids)\n",
    "source_dataset = source_dataset.map(process, batched=True, batch_size=None, fn_kwargs={\"is_source_dataset\": True})"
   ],
   "id": "28809d6589733d79",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 185397/185397 [00:00<00:00, 333011.31 examples/s]\n"
     ]
    }
   ],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T07:15:36.275694Z",
     "start_time": "2025-11-28T07:15:07.226390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_data = []\n",
    "for i in range(len(target_dataset)):\n",
    "    new_data.append({\n",
    "        \"title\": target_dataset[i][\"text\"],\n",
    "        \"text\": source_dataset[i][\"text\"]\n",
    "    })\n",
    "\n",
    "dataset = Dataset.from_list(new_data)"
   ],
   "id": "merge_clts_dataset",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T08:25:15.908150Z",
     "start_time": "2025-11-28T08:25:13.480212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = dataset.filter(\n",
    "    lambda examples: [len(text) >= 50 and len(title) >= 10 for title, text in zip(examples[\"title\"], examples[\"text\"])],\n",
    "    batched=True,\n",
    "    batch_size=None\n",
    ")"
   ],
   "id": "f7705cb0e7006c88",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 185173/185173 [00:02<00:00, 76797.91 examples/s]\n"
     ]
    }
   ],
   "execution_count": 239
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T08:25:17.565307Z",
     "start_time": "2025-11-28T08:25:17.556456Z"
    }
   },
   "cell_type": "code",
   "source": "len(dataset)",
   "id": "6a6c7ad07473e3a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184556"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 240
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T08:25:35.661666Z",
     "start_time": "2025-11-28T08:25:21.437064Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.to_parquet(output_path)",
   "id": "2aa1ae8e855015bf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 185/185 [00:14<00:00, 13.02ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "870207223"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 241
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dianping",
   "id": "d9648cc1e0666773"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "input_path = \"\"\n",
    "output_path = \"\""
   ],
   "id": "106f50f35dd34c0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = load_dataset(\"parquet\", data_files=input_path)[\"train\"]",
   "id": "7d990d48e498597a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import ast\n",
    "\n",
    "dataset = dataset.filter(\n",
    "    lambda examples: [len(ast.literal_eval(object)) != 0 for object in examples[\"object\"]],\n",
    "    batched=True,\n",
    "    batch_size=None\n",
    ")"
   ],
   "id": "7df157206408d83c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(dataset)",
   "id": "41ac3f1dc18ebcaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process(examples: dict[str, list]) -> dict[str, list]:\n",
    "    examples[\"text\"] = [\n",
    "        ast.literal_eval(f'\"{sentence.replace('\"', '\\\\\"').replace(\"'\", \"\\\\'\")}\"')\n",
    "        for sentence in examples[\"sentence\"]\n",
    "    ]  # e.g. '\\\\n' -> '\\n'\n",
    "    objects = examples[\"object\"]\n",
    "    titles = []\n",
    "    for object_str in objects:\n",
    "        object_list = ast.literal_eval(object_str)\n",
    "        titles.append(\"，\".join(object_list))\n",
    "    examples[\"title\"] = titles\n",
    "    return examples"
   ],
   "id": "4f48f362f5462a10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = dataset.map(process, batched=True, batch_size=None, remove_columns=dataset.column_names)",
   "id": "3567216aeec30799"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset.to_parquet(output_path)",
   "id": "2d1db0ba21acdcdc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
